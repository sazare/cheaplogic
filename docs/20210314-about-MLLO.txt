機械/深層学習と自動証明のコンビネーションについて

1.最初の考え
　1,2年前に、自動証明と深層学習を組み合わせた研究の論文をみていたが
　証明自体を学習するという話はいくつかあった。
　自動証明の計算量が多いので、それを解決するということだと思う。
　ただ、無矛盾性はともかく、完全性などは考慮されていないようだった。
　
　深層学習でなんでも学習してやるという風潮があるようで、その一貫であり
　自動証明とうまく組み合わさっている感じはしなかった。

　深層学習は、高度なセンサーだと思えば、世界の観察により、そこからFactを取り出す
　技術だとも考えられる。
　そのように得られたFactから、自動証明によって何か命題を求めることは、意味があるかもしれない。

　演繹システムは、証明が目的なので、元の公理系にない事実を導入してはいけない。
　だから、演繹システムは情報を加えないのであり、与えられた公理が含んでいる命題しか導けない。

　人間にとって自明でない命題を証明することはできるだろうが、
　それは、人間には、なぜそのような結論になったのかわからないタイプの証明なのかもしれない。

　センサーから得られるFactはすこし前のシステムにはなかった命題であり、論理システムは
　情報を追加しないかもしれないが、ML-LOシステムとしては新しい情報を取り入れている。
　そして推論自体はその情報以外の、恣意的な真実といえるかどうかわからないFactもどきは
　含んでいない。というシステムを考えることができる。

では、これは妥当な考えなのか?


2. 妥当だとしても、調べていくと、思ったより手に負えない感じがする
・ML002のようなものを考えるとき、+PP(p, a) でaがPPである確率をpと書くとすると
・+PP(0.4,a) => +PP(0.6, a) => +PP(0.8, a)
　と変化したとき、これらのfactは蓄積されてはまずいので、置き換わらなくてはならない。
　矛盾していなくても置き換わる。
　置き換わらなくてはならないかどうかは自明でない。

・置き換わるときの前提として、+PP(p, a)は1つしか存在してはならないという前提がある。
　つまりaについて+PPは1つのfactしか許さない。
　これは、PPがuniqueなaについての性質であるという性質。
・+R(p, a, b)というような「関係」の場合、(a,b)というペアについてuniqueな性質というものがあるか。
・uniqueというのは、(a,b)について1つしか関係がないという意味でなく、(a,b)のRという関係は1種類しかないとい>うこと。


★前提としているかもしれないことを明確にすることが必要。

・これは、Axiom Setのupdate。
　Factのupdate。
　Factが変わるというのは、矛盾するものは消すということ
　何を消せばいいのかは自明ではない

・つまり、モデルについて成り立っている条件を使えば、直感的な推論にそうこともできる
　それをaxiomとして追加する罪?
　意義はあるのか?


3. できることはなにか?
・どのようなgoalを選んで証明しようとするのか?
・新しいfactはDLから次々と流れてくるが、システムが証明したいものは何か?
・Goalはシステムとは別の文脈で発生しなくてはなるまい。
　演繹システムは情報を足さないので、同じ穴からでたgoalではあまり意味がない。はず。
★　　反例はあるか?

・では、システムの外で選ぶgoalとは何か?

・これは、自立型システムであり、世界とのinteractionがあるようなもの
　つまり、ロボットでの課題だと思う。ロボットにいては後記


・自動証明の枠で考えるならば
　・述語があらかじめ決まっている。
　・Factの形(unit clause)は、システム内で生まれるgoal
　・Fact収集のフェーズはありそう。
　　・新しい述語が導入されたとき、その述語に関する公理を作るフェーズ。
 　 ・仮説というのは、Factの形をした命題か、変数を含むもので
　　　(1) 公理システムで証明があるもの
          これに対して深層学習でその仮説が成り立つかどうかを聞く
　　　　　深層学習に対して、「これは成り立つか」という質問は
　　　　　命題をモデルの言葉に翻訳して、学習推論によるその命題の確からしさを求める
　　　　　ということになりそう。
　　　　深層学習で、「何々」の確率を求めるとは、どういうことか?
         ? classificationではなく、判定ってカテゴリあったっけ?
　　　　　　aはクラスAに属しているかどうか? decision treeみたいのはあるのでこの問はある。
　　　　　　もし、「何何」が変数を含んでいたら、困るかな。

　　　　・すべてのinstanceはそれであるかどうかの確率pをもつ。ということは
　　　　　a => (p,a)で表される。
　　　　　センサーで得た情報が(q,a)で、q>=pのとき(p,a)は存在すると考えられる。

　　　　・pが確率だと書いたけれど、確率ではなくp+qi　複素数かもしれない。
　　　　　　確率でなく、何か

　　　　　　
　　　　 ? 「何何」をどうすれば深層学習で判定できるようになるのか?


　　　(2) 公理システムで証明ができないもの
　　　　この場合、その命題が深層学習で得られるなら新しいfactの追加になる。


★ Factと仮説の違い
　・Factは世界からDLが解釈したground命題
　・仮説は、一般化されて変数を含まなけれは
　　　判定問題。深層学習の対象世界の表現に変換する。

　・仮説は、一般化されて変数を含むと、センサーのハンドルとして定義し
　　いずれ仮説条件がfalseになると、反証発見とtriggerされる。

　・仮説が -P(f(x))のとき、センサーが+P(f(a))をみつけたらfalseでトリガー。
　　-P(x)はセンサーは発見できない。

　　+P(b)は+P(a)がみつかったとき反証される? ドメインに対する仮説が必要。
　　　Pが、ドメインの要素についてどれか1つでしか成り立たないなら、+P(a)なら+P(b)ではない。
　　　-P(b)が言える。
　　一般には、+P(a)かつ+P(b)はありうるので、このような推論はできない。
　　　これは、今のproverの標準。

　　　
　　-P(f(x))に対して、センサー+P(g(a))は関係しないので無視
　　　これもresolutionデフォルト動作



　


[ロボット]
・自立型ロボットの場合、考えているのは
　判定システムのレイヤー化。これは動物と同じ
　動物は本能とか理性というようなレイヤーに分かれた判定システムを持っている。
　上側の判定は、下位の判定システムを教師として学習がすすむ。
　人間の本能は、胎児の期間に構成されると思うが、根本は、「苦楽」だと思う。
　生存に必要な究極の基準は、「気持ちいい」か「苦しい」になっている。

　出産直後、酸欠で苦しい。それを解決する方法が「泣く」という行為。
　このときの「なく」は呼吸するという行為と重ね合わされている。
　この「なく」という行為は一択であり、その後与えられるすべての苦を解決する手段でもある。

　一般的に動物は出産直後、なくものだろうか?

　そういえば、鳥は四六時中「鳴いている」ような気がする。

　

　「なく」に対する世界の反応が親による解決
　「排尿」「排便」は「楽」だが、その後、人間の場合は、おむつにたまった排泄物による
　いやなかんじ「苦」が生じ「なく」

　「空腹」は「苦」であり、乳を飲むことで「苦」が消滅するが、それも「なく」と「乳」が
　与えられる。

　「乳」を吸う行為は、もっと根源的な部分でプログラムされているのかもしれない。

　「泣く」以外に「笑う」が行為の選択肢にでてくる。
　「視覚」から得られるデータの類別ができるようになるのは、「笑う」がひきおこす
　世界の変化と、「苦楽」の関連付けからか。



　などなど
